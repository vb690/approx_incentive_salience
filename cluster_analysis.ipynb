{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.linalg' has no attribute 'decomp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f7c3cbbeb2ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsupervised\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengagement_clusterers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauto_kmeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\to_commit\\modules\\models\\unsupervised\\engagement_clusterers.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclusterers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauto_elbow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\penthotal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\penthotal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m _DEFAULT_TAGS = {\n",
      "\u001b[1;32mc:\\users\\penthotal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m from .validation import (as_float_array,\n\u001b[0;32m     27\u001b[0m                          \u001b[0massert_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\penthotal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# Preserves earlier default choice of pinvh cutoff `cond` value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# Can be removed once issue #14055 is fully addressed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scipy_linalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpinvh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpinvh\u001b[0m \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\penthotal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\_scipy_linalg.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomp\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdecomp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.linalg' has no attribute 'decomp'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from modules.models.unsupervised.engagement_clusterers import auto_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sns_styleset():\n",
    "    sns.set(context='paper', style='ticks', font='DejaVu Sans')\n",
    "    matplotlib.rcParams['figure.dpi']        = 300\n",
    "    matplotlib.rcParams['axes.linewidth']    = 1\n",
    "    matplotlib.rcParams['xtick.major.width'] = 1\n",
    "    matplotlib.rcParams['ytick.major.width'] = 1\n",
    "    matplotlib.rcParams['xtick.major.size']  = 3\n",
    "    matplotlib.rcParams['ytick.major.size']  = 3\n",
    "    matplotlib.rcParams['xtick.minor.size']  = 2\n",
    "    matplotlib.rcParams['ytick.minor.size']  = 2\n",
    "    matplotlib.rcParams['font.size']         = 11\n",
    "    matplotlib.rcParams['axes.titlesize']    = 11\n",
    "    matplotlib.rcParams['axes.labelsize']    = 12\n",
    "    matplotlib.rcParams['legend.fontsize']   = 10\n",
    "    matplotlib.rcParams['xtick.labelsize']   = 10\n",
    "    matplotlib.rcParams['ytick.labelsize']   = 10\n",
    "    \n",
    "sns_styleset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - LOAD GLOBALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS_PATH = 'data\\\\train\\\\inputs\\\\{}'\n",
    "TARGETS_PATH = 'data\\\\train\\\\targets\\\\{}'\n",
    "\n",
    "CMAP = matplotlib.cm.get_cmap('Paired')\n",
    "\n",
    "BTCH = [i for i in range(len(os.listdir(INPUTS_PATH.format('continuous_features'))))]\n",
    "BTCH = BTCH[0::20]\n",
    "\n",
    "SNAPSHOTS = 10\n",
    "\n",
    "INPUTS = [\n",
    "    'delta_sessions',\n",
    "    'active_time',\n",
    "    'session_time',\n",
    "    'activity'\n",
    "]\n",
    "TARGETS = [\n",
    "    'tar_sessions',\n",
    "    'tar_delta_sessions',    \n",
    "    'tar_active_time',\n",
    "    'tar_session_time',\n",
    "    'tar_activity'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - LOAD REMAPPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS_RMP = {\n",
    "    'tar_delta_sessions': 'Future Absence',    \n",
    "    'tar_active_time': 'Future Active Time',\n",
    "    'tar_session_time': 'Future Session Time',\n",
    "    'tar_activity': 'Future Session Activity',\n",
    "    'tar_sessions': 'Future N° Sessions'\n",
    "}\n",
    "INPUTS_RMP = {\n",
    "    'tar_delta_sessions': 'Absence',    \n",
    "    'tar_active_time': 'Active Time',\n",
    "    'tar_session_time': 'Session Time',\n",
    "    'tar_activity': 'Session Activity',\n",
    "    'tar_sessions': 'N° Sessions'\n",
    "}\n",
    "with open('results\\\\saved_objects\\\\mappers\\\\context.pkl', 'rb') as pickle_file:\n",
    "    CONTEXT_RMP = pickle.load(pickle_file) \n",
    "CONTEXT_RMP = {value: key for key, value in CONTEXT_RMP.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open('results\\\\saved_data_containers\\\\melchior.pkl', 'rb')) as container:\n",
    "    DATA_CONTAINER = pickle.load(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_remap = {\n",
    "    1: 'Hitman Sniper',\n",
    "    2: 'JustCause 3',\n",
    "    3: 'LIS BeSt',\n",
    "    4: 'LIS',\n",
    "    5: 'JustCause 4',\n",
    "    6: 'Hitman Go',\n",
    "}\n",
    "contexts = DATA_CONTAINER['context'][0]\n",
    "color = DATA_CONTAINER['prediction']['tar_session_time'][0]\n",
    "# color = group_wise_binning(\n",
    "#     array=color,\n",
    "#     grouper=contexts,\n",
    "#     n_bins=100,\n",
    "#     method='discret'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - CLUSTER PROFILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_CONTAINER['partitions'] = {}\n",
    "for snapshot in [3]:\n",
    "    \n",
    "    reduction = np.load(f'results\\\\saved_dim_reduction\\\\2D\\\\umap_melchior_eng_emb_{snapshot}.npy')\n",
    "    reduction = reduction[~np.isnan(reduction).any(axis=1)]\n",
    "    \n",
    "    features = np.load(f'results\\\\saved_dim_reduction\\\\10D\\\\umap_melchior_eng_emb_{snapshot}.npy')\n",
    "    features = features[~np.isnan(features).any(axis=1)]\n",
    "    \n",
    "    contexts = DATA_CONTAINER['context'][snapshot]\n",
    "    \n",
    "    DATA_CONTAINER['partitions'][snapshot] = np.empty(contexts.shape)\n",
    "    \n",
    "    index = 0\n",
    "    for context in np.unique(contexts):\n",
    "        \n",
    "        context_idx = np.argwhere(contexts == context).flatten()\n",
    "        context_name = CONTEXT_RMP[context]\n",
    "        context_features = features[context_idx, :]\n",
    "        context_features = (context_features - context_features.mean(axis=0)) / context_features.std(axis=0)\n",
    "        \n",
    "        #clustering\n",
    "        clusterer, partition_labels, centroids = auto_kmeans(\n",
    "            X=context_features, \n",
    "            min_k=2, \n",
    "            max_k=10, \n",
    "            verbose=1, \n",
    "            fast=True, \n",
    "            save_name=f'{context_name}_step_{snapshot+1}',\n",
    "            max_no_improvement=100,\n",
    "            batch_size=1000,\n",
    "            max_iter=3000,\n",
    "            n_init=3000,\n",
    "            reassignment_ratio=0.1\n",
    "        )\n",
    "        \n",
    "        DATA_CONTAINER['partitions'][snapshot][context_idx] = partition_labels\n",
    "        \n",
    "        # define the gridspec\n",
    "        fig = plt.figure(figsize=(15, 6))\n",
    "        spec = fig.add_gridspec(ncols=10, nrows=2)\n",
    "        \n",
    "        ax_context = fig.add_subplot(spec[:, :4])\n",
    "        axs_metrics = [\n",
    "            fig.add_subplot(spec[0, 4:6]),\n",
    "            fig.add_subplot(spec[0, 6:8]),\n",
    "            fig.add_subplot(spec[0, 8:]),\n",
    "            fig.add_subplot(spec[1, 5:7]),\n",
    "            fig.add_subplot(spec[1, 7:9])\n",
    "        ]\n",
    "        \n",
    "        # plotting context\n",
    "        ax_context.scatter(\n",
    "            np.delete(reduction, context_idx, axis=0)[:, 0],\n",
    "            np.delete(reduction, context_idx, axis=0)[:, 1],\n",
    "            s=0.25,\n",
    "            alpha=0.5,\n",
    "            marker='o',\n",
    "            edgecolor='',\n",
    "            color='darkgray',\n",
    "        )\n",
    "        \n",
    "        for partition_label in np.unique(partition_labels):\n",
    "            \n",
    "            partition_idx = np.argwhere(partition_labels == partition_label).flatten()\n",
    "            context_partition_reduction = reduction[context_idx, :][partition_idx, :]\n",
    "            ax_context.scatter(\n",
    "                context_partition_reduction[:, 0],\n",
    "                context_partition_reduction[:, 1],\n",
    "                s=0.25,\n",
    "                marker='o',\n",
    "                edgecolor='',\n",
    "                c=CMAP([partition_label] * len(partition_idx)),\n",
    "                label=f'Partition {partition_label+1}',\n",
    "            )\n",
    "        \n",
    "        index = 0\n",
    "        for target_name, ax_metric in zip(TARGETS, axs_metrics):\n",
    "        \n",
    "            for partition_label in np.unique(partition_labels):\n",
    "\n",
    "                partition_idx = np.argwhere(partition_labels == partition_label).flatten()\n",
    "                context_partition_reduction = reduction[context_idx, :][partition_idx, :]\n",
    "\n",
    "                prediction = DATA_CONTAINER['prediction'][target_name][snapshot]\n",
    "                context_prediction = prediction[context_idx, :]\n",
    "\n",
    "                if target_name != 'tar_sessions':\n",
    "                    metric_name = target_name[4:]\n",
    "                    metric = DATA_CONTAINER['input_metrics'][metric_name][snapshot]\n",
    "\n",
    "                    context_metric = metric[context_idx, :]\n",
    "\n",
    "                    context_line = np.hstack(\n",
    "                        (context_metric, context_prediction)\n",
    "                    )\n",
    "                    context_mean = np.mean(context_line, axis=0)\n",
    "                    context_std = np.std(context_line, axis=0)\n",
    "\n",
    "                    context_partition_line = context_line[partition_idx, :]\n",
    "                    context_partition_line = (context_partition_line - context_mean) / context_std\n",
    "\n",
    "                    if metric_name == 'delta_sessions':\n",
    "                        context_partition_line = context_partition_line[:, 1:]\n",
    "                        steps = [step for step in range(2, context_partition_line.shape[1] +2)]\n",
    "                    else:\n",
    "                        steps = [step for step in range(1, context_partition_line.shape[1] +1)]\n",
    "                    context_partition_sem = sem(\n",
    "                        context_partition_line\n",
    "                    )\n",
    "                    context_partition_line = np.mean(\n",
    "                        context_partition_line, \n",
    "                        axis=0\n",
    "                    )\n",
    "\n",
    "                    ax_metric.plot(\n",
    "                        steps[:-1],\n",
    "                        context_partition_line[:-1],\n",
    "                        c=CMAP(partition_label)\n",
    "                    )\n",
    "                    ax_metric.fill_between(\n",
    "                        steps[:-1],\n",
    "                        context_partition_line[:-1] + (1.96 * context_partition_sem[:-1]),\n",
    "                        context_partition_line[:-1] - (1.96 * context_partition_sem[:-1]),\n",
    "                        color=CMAP(partition_label),\n",
    "                        alpha=0.25\n",
    "                    )\n",
    "                    ax_metric.plot(\n",
    "                        [steps[-2], steps[-1]],\n",
    "                        [context_partition_line[-2],context_partition_line[-1]],\n",
    "                        c=CMAP(partition_label),\n",
    "                        linestyle='--',\n",
    "                        marker='o',\n",
    "                        markersize=2\n",
    "                    )\n",
    "                    ax_metric.fill_between(\n",
    "                        np.array([steps[-2], steps[-1]]),\n",
    "                        np.array([context_partition_line[-2],context_partition_line[-1]]) + (1.96 * np.array([context_partition_sem[-2],context_partition_sem[-1]])),\n",
    "                        np.array([context_partition_line[-2],context_partition_line[-1]]) - (1.96 * np.array([context_partition_sem[-2],context_partition_sem[-1]])),\n",
    "                        color=CMAP(partition_label),\n",
    "                        alpha=0.25\n",
    "                    )\n",
    "                else:\n",
    "                    context_line = np.zeros(\n",
    "                        shape=(context_prediction.shape[0], snapshot + 1)\n",
    "                    )\n",
    "                    context_line[:, -1] = context_prediction.flatten()\n",
    "                    for r_index in range(snapshot -1,-1,-1):\n",
    "\n",
    "                        context_line[:, r_index] = context_line[:, r_index+1] + 1\n",
    "\n",
    "                    context_mean = np.mean(context_line[:, -1])\n",
    "                    context_std = np.std(context_line[:, -1])\n",
    "                    context_partition_line = context_line[partition_idx, :]\n",
    "                    context_partition_line = (context_partition_line - context_mean) / context_std\n",
    "                    steps = [step for step in range(1, context_partition_line.shape[1] +1)]\n",
    "\n",
    "                    context_partition_sem = sem(\n",
    "                        context_partition_line\n",
    "                    )\n",
    "                    context_partition_line = np.mean(\n",
    "                        context_partition_line, \n",
    "                        axis=0\n",
    "                    )\n",
    "\n",
    "                    ax_metric.bar(\n",
    "                        partition_label,\n",
    "                        context_partition_line[-1],\n",
    "                        color=CMAP(partition_label),\n",
    "                        yerr=1.96*context_partition_sem[-1]\n",
    "                    )\n",
    "\n",
    "            yabs_max = abs(max(ax_metric.get_ylim(), key=abs))\n",
    "            ax_metric.set_ylim(ymin=-yabs_max, ymax=yabs_max)\n",
    "            ax_metric.axhline(\n",
    "                0,\n",
    "                c='k',\n",
    "                linestyle=':'\n",
    "            )\n",
    "\n",
    "            metric_name = INPUTS_RMP[target_name]\n",
    "            ax_metric.set_title(f'{metric_name} - $t$ {snapshot+1}')\n",
    "            if index == 0:\n",
    "                ax_metric.set_xticks([])\n",
    "            else:\n",
    "                ax_metric.set_xlabel('Session')\n",
    "\n",
    "            index +=1\n",
    "        \n",
    "        ax_context.set_title(f'Partition Game Context {context_name} - $t$ {snapshot+1}')\n",
    "        ax_context.set_xlabel('Dimension 1')\n",
    "        ax_context.set_ylabel('Dimension 2')\n",
    "        ax_context.legend(markerscale=8)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f'results\\\\figures\\\\clusterer\\\\clusterer_profiles\\\\{CONTEXT_RMP[context]}_{snapshot+1}.png',\n",
    "            dpi=500,\n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
